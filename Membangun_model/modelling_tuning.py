# -*- coding: utf-8 -*-
"""modelling_tuning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dX5JmmnBWDUpmY8c4bgEpxEFT2fQyJ-A

1. Import Library
"""

# Import Library
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
!pip install mlflow
import mlflow
import mlflow.sklearn
!pip install dagshub
import dagshub
import os

from mlflow.entities import param
from os import path
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score

"""2. Set-up dan Konfigurasi"""

# Setup dan konfigurasi
dagshub_username = "alimaruf.jpn"
dagshub_reponame = "Eksperimen_SML_Muhammad_Ali_M"

"""3. Training dan Tunning model"""

def train_n_tune ():
  print('Proses Tuning')
  dagshub.init(repo_name=dagshub_reponame, repo_owner=dagshub_username, mlflow = True)
  mlflow.set_experiment('water_potability_tuning')
  # Validasi data
  data_path = 'water_potability_preprocessing.csv'
  print('data ditemukan')
  if not os.path.exists(data_path):
    data_path = '/content/water_potability_preprocessing.csv'
    print('data asli tidak ditemukan')

  # Memuat dataset
  print('Loading data : ', data_path)
  df = pd.read_csv(data_path)
  print('Data berhasil dimuat')

  # Pisahkan fitur dan target
  X = df.drop('Potability', axis=1)
  y = df['Potability']

  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

  param = {'n_estimators': [50,100],
      'max_depth': [None,10],
      'min_samples_split': [2,5]}
  rf = RandomForestClassifier()
  grid_search = GridSearchCV(estimator=rf, param_grid=param, cv=3, scoring='accuracy', verbose=1)

  with mlflow.start_run(run_name='RF_grid_tuning'):
    grid_search.fit(X_train, y_train)

    best_model = grid_search.best_estimator_
    best_params = grid_search.best_params_

    y_pred = best_model.predict(X_test)
    acc_score = accuracy_score(y_test, y_pred)
    prec_score = precision_score(y_test, y_pred)
    rec_score = recall_score(y_test, y_pred)
    f_score = f1_score(y_test, y_pred)

    print('Best Parameters: ', best_params)
    print('Accuracy Score: ', acc_score)
    print('Precision Score: ', prec_score)
    print('Recall Score: ', rec_score)
    print('F1 Score: ', f_score)

    mlflow.log_params(best_params)
    mlflow.log_metric('accuracy', acc_score)
    mlflow.log_metric('precision', prec_score)
    mlflow.log_metric('recall', rec_score)
    mlflow.log_metric('f1', f_score)

    mlflow.sklearn.log_model(best_model, 'best_model')
    print('Model berhasil disimpan')

    # Artifak 1
    plt.figure(figsize=(10, 10))
    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.savefig('confusion_matrix.png')
    mlflow.log_artifact('confusion_matrix.png')
    print('Artifak berhasil disimpan')

    # Artifak 2
    feature_names = X.columns
    importances = best_model.feature_importances_
    indices = importances.argsort()[::-1]

    plt.figure(figsize=(10, 10))
    plt.title('Feature Importance')
    plt.bar(range(X.shape[1]), importances[indices], align="center")
    plt.xticks(range(X.shape[1]), feature_names[indices], rotation=90)
    plt.tight_layout()
    plt.savefig('feature_importance.png')
    mlflow.log_artifact('feature_importance.png')
    print('Artifak berhasil disimpan')

    os.remove('confusion_matrix.png')
    os.remove('feature_importance.png')
    print('Artifak berhasil dihapus')


if __name__ == '__main__':
  train_n_tune()